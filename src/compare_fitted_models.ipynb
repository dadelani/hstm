{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.decomposition import NMF, PCA\n",
    "from sklearn.linear_model import Ridge, LogisticRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_error as mse, roc_auc_score as roc, accuracy_score as acc, log_loss\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data.dataset import TextResponseDataset\n",
    "import causal_attribution\n",
    "import util\n",
    "from scipy.sparse import csr_matrix\n",
    "from importlib import reload\n",
    "import data.dataset as ds\n",
    "from model.topic_model import TopicModel\n",
    "from model.adjusted_hstm import HeterogeneousSupervisedTopicModel\n",
    "from model.model_trainer import ModelTrainer\n",
    "from torch.utils.data import DataLoader\n",
    "import evaluation.evaluator as ev\n",
    "from evaluation.evaluator import Evaluator\n",
    "import itertools as it\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "classification_settings = {'peerread', 'amazon_binary', 'yelp','framing_corpus'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 19969, 6057)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(ds)\n",
    "\n",
    "dataset = 'yelp'\n",
    "\n",
    "framing_topic = 'deathpenalty'\n",
    "\n",
    "if dataset == 'amazon':\n",
    "    datafile = '../dat/reviews_Office_Products_5.json'\n",
    "elif dataset == 'amazon_binary':\n",
    "    datafile = '../dat/reviews_Grocery_and_Gourmet_Food_5.json'\n",
    "elif dataset == 'yelp':\n",
    "    datafile = '../dat/yelp_review_polarity_csv/train.csv'\n",
    "elif dataset == 'peerread':\n",
    "    datafile = '../dat/peerread_abstracts.csv'\n",
    "elif dataset == 'framing_corpus':\n",
    "    datafile = '../dat/framing/'\n",
    "else:\n",
    "    datafile = '../dat/cs_papers.gz'\n",
    "\n",
    "if dataset == 'framing_corpus':\n",
    "    proc_file = '../dat/proc/' + dataset + '_' + framing_topic + '_proc.npz'\n",
    "else:\n",
    "    proc_file = '../dat/proc/' + dataset + '_proc.npz'\n",
    "\n",
    "components = {'amazon':30, \n",
    "              'semantic_scholar':50, \n",
    "              'peerread':50, 'yelp':30, \n",
    "              'amazon_binary':20, \n",
    "              'framing_corpus':10\n",
    "             }\n",
    "text_dataset = ds.TextResponseDataset(dataset, \n",
    "                                      datafile, \n",
    "                                      proc_file, \n",
    "                                      use_bigrams=False,\n",
    "                                      framing_topic=framing_topic)\n",
    "\n",
    "counts = text_dataset.counts\n",
    "labels= text_dataset.labels\n",
    "vocab= text_dataset.vocab\n",
    "docs = text_dataset.docs\n",
    "\n",
    "n_components=components[dataset]\n",
    "num_documents = counts.shape[0]\n",
    "n_components, num_documents, counts.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=counts.shape[1]\n",
    "\n",
    "stm = HeterogeneousSupervisedTopicModel(n_components, \n",
    "                                        vocab_size, \n",
    "                                        num_documents,\n",
    "                                        response_model='stm')\n",
    "hstm = HeterogeneousSupervisedTopicModel(n_components, \n",
    "                                        vocab_size, \n",
    "                                        num_documents,\n",
    "                                        response_model='hstm-all')\n",
    "\n",
    "trainer_stm = ModelTrainer(stm,\n",
    "                       use_pretrained=True,\n",
    "                       do_pretraining_stage=False,\n",
    "                       do_finetuning=True,\n",
    "                       model_name='stm',\n",
    "                       load=True,\n",
    "                        model_file='../out/model/stm.yelp.0.model')\n",
    "\n",
    "trainer_hstm = ModelTrainer(hstm,\n",
    "                       use_pretrained=True,\n",
    "                       do_pretraining_stage=False,\n",
    "                       do_finetuning=True,\n",
    "                       model_name='hstm-all',\n",
    "                       load=True,\n",
    "                        model_file='../out/model/hstm-all.yelp.0.model')\n",
    "\n",
    "\n",
    "trainer_stm.train(None)\n",
    "trainer_hstm.train(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(ev)\n",
    "\n",
    "evaluator_stm = ev.Evaluator(stm, \n",
    "                      text_dataset.vocab,\n",
    "                      text_dataset.counts, \n",
    "                      text_dataset.labels, \n",
    "                      text_dataset.docs,\n",
    "                      model_name='stm')\n",
    "\n",
    "stm_topics = evaluator_stm.get_topics()\n",
    "\n",
    "\n",
    "evaluator_hstm = ev.Evaluator(hstm, \n",
    "                      text_dataset.vocab,\n",
    "                      text_dataset.counts, \n",
    "                      text_dataset.labels, \n",
    "                      text_dataset.docs,\n",
    "                      model_name='hstm-all')\n",
    "\n",
    "hstm_topics = evaluator_hstm.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Topic 0: sushi roll bar place people get like\n",
      "Topic 1: coffee staff location starbucks cafe ha espresso\n",
      "Topic 2: burger fry wa potato sweet bacon cheese\n",
      "Topic 3: last night happy hour hour time went time wa\n",
      "Topic 4: der nicht und die ich ist auch\n",
      "Topic 5: egg breakfast pancake toast wa bacon benedict\n",
      "Topic 6: nail massage salon pedicure gel wa pedi\n",
      "Topic 7: customer order location service cashier manager counter\n",
      "Topic 8: show wa car but get see told\n",
      "Topic 9: le en de la qui une pa\n",
      "Topic 10: minute u waited order finally wait table\n",
      "Topic 11: bar club dance night girl wa dj\n",
      "Topic 12: sandwich pie wa sandwich wa soup chocolate soup wa\n",
      "Topic 13: great place food love always good price\n",
      "Topic 14: wa roll dish sushi but chef sauce\n",
      "Topic 15: wa food horrible mexican tasted like bland like\n",
      "Topic 16: flight airline bag plane airport fly charge\n",
      "Topic 17: wa steak steak wa appetizer wine great filet\n",
      "Topic 18: dog movie theater animal vet cat hospital\n",
      "Topic 19: call told wa company insurance would could\n",
      "Topic 20: room front wa front desk stay hotel room wa\n",
      "Topic 21: pizza crust slice pepperoni pizza wa topping italian\n",
      "Topic 22: wa class room pool kid course but\n",
      "Topic 23: great highly staff love service recommend great service\n",
      "Topic 24: bar seating coffee great park plenty sport\n",
      "Topic 25: taco chip table guacamole wa salsa brought\n",
      "Topic 26: store sale dress item price selection shirt\n",
      "Topic 27: fried rice thai curry fried rice wa bowl\n",
      "Topic 28: chocolate location lot get like parking go\n",
      "Topic 29: wa wing sandwich but good chicken chicken wa\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Topic 0&sushi&roll&bar&place&people&get&like\\\\\\\\\\nTopic 1&coffee&staff&location&starbucks&cafe&ha&espresso\\\\\\\\\\nTopic 2&burger&fry&wa&potato&sweet&bacon&cheese\\\\\\\\\\nTopic 3&last&night&happy hour&hour&time went&time&wa\\\\\\\\\\nTopic 4&der&nicht&und&die&ich&ist&auch\\\\\\\\\\nTopic 5&egg&breakfast&pancake&toast&wa&bacon&benedict\\\\\\\\\\nTopic 6&nail&massage&salon&pedicure&gel&wa&pedi\\\\\\\\\\nTopic 7&customer&order&location&service&cashier&manager&counter\\\\\\\\\\nTopic 8&show&wa&car&but&get&see&told\\\\\\\\\\nTopic 9&le&en&de&la&qui&une&pa\\\\\\\\\\nTopic 10&minute&u&waited&order&finally&wait&table\\\\\\\\\\nTopic 11&bar&club&dance&night&girl&wa&dj\\\\\\\\\\nTopic 12&sandwich&pie&wa&sandwich wa&soup&chocolate&soup wa\\\\\\\\\\nTopic 13&great&place&food&love&always&good&price\\\\\\\\\\nTopic 14&wa&roll&dish&sushi&but&chef&sauce\\\\\\\\\\nTopic 15&wa&food&horrible&mexican&tasted like&bland&like\\\\\\\\\\nTopic 16&flight&airline&bag&plane&airport&fly&charge\\\\\\\\\\nTopic 17&wa&steak&steak wa&appetizer&wine&great&filet\\\\\\\\\\nTopic 18&dog&movie&theater&animal&vet&cat&hospital\\\\\\\\\\nTopic 19&call&told&wa&company&insurance&would&could\\\\\\\\\\nTopic 20&room&front&wa&front desk&stay&hotel&room wa\\\\\\\\\\nTopic 21&pizza&crust&slice&pepperoni&pizza wa&topping&italian\\\\\\\\\\nTopic 22&wa&class&room&pool&kid&course&but\\\\\\\\\\nTopic 23&great&highly&staff&love&service&recommend&great service\\\\\\\\\\nTopic 24&bar&seating&coffee&great&park&plenty&sport\\\\\\\\\\nTopic 25&taco&chip&table&guacamole&wa&salsa&brought\\\\\\\\\\nTopic 26&store&sale&dress&item&price&selection&shirt\\\\\\\\\\nTopic 27&fried rice&thai&curry&fried&rice&wa&bowl\\\\\\\\\\nTopic 28&chocolate&location&lot&get&like&parking&go\\\\\\\\\\nTopic 29&wa&wing&sandwich&but&good&chicken&chicken wa\\\\\\\\\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_stm.visualize_topics(format_pretty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Topic 0: sushi people roll night place one but\n",
      "Topic 1: coffee ha shop cafe but staff one\n",
      "Topic 2: burger fry cheese ice sweet but cream\n",
      "Topic 3: night last last time time went first time time happy hour\n",
      "Topic 4: ist und ich da auch man nicht\n",
      "Topic 5: egg toast breakfast benedict biscuit pancake waffle\n",
      "Topic 6: nail gel massage polish pedicure salon pedi\n",
      "Topic 7: customer order customer service minute order wa manager service\n",
      "Topic 8: show car but wa one get said\n",
      "Topic 9: la le de un est dans je\n",
      "Topic 10: minute u finally order took waitress waiting\n",
      "Topic 11: club night dance drink bar girl beer\n",
      "Topic 12: sandwich sandwich wa soup bread pie turkey chocolate\n",
      "Topic 13: great always good but pretty good pho place\n",
      "Topic 14: wa lobster but shrimp pasta piece sauce\n",
      "Topic 15: bad food tasted like bland wa horrible tasted\n",
      "Topic 16: flight airline plane la fly airport ticket\n",
      "Topic 17: steak wa wine but dining dinner service wa\n",
      "Topic 18: dog movie theater cat animal hospital vet\n",
      "Topic 19: company call called would day said sent\n",
      "Topic 20: room stay front hotel night front desk desk\n",
      "Topic 21: pizza pepperoni crust pizza wa topping thin oven\n",
      "Topic 22: room but class lot gym wa floor\n",
      "Topic 23: great amazing recommend always highly best beer\n",
      "Topic 24: park seating coffee great bar outdoor plenty\n",
      "Topic 25: taco salsa chip table tortilla u burrito\n",
      "Topic 26: store item buy shoe selection dress sale\n",
      "Topic 27: thai rice chicken but noodle fried rice sauce\n",
      "Topic 28: lot chocolate parking one get yogurt go\n",
      "Topic 29: wa but good wing wa good chicken pretty good\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Topic 0&sushi&people&roll&night&place&one&but\\\\\\\\\\nTopic 1&coffee&ha&shop&cafe&but&staff&one\\\\\\\\\\nTopic 2&burger&fry&cheese&ice&sweet&but&cream\\\\\\\\\\nTopic 3&night&last&last time&time went&first time&time&happy hour\\\\\\\\\\nTopic 4&ist&und&ich&da&auch&man&nicht\\\\\\\\\\nTopic 5&egg&toast&breakfast&benedict&biscuit&pancake&waffle\\\\\\\\\\nTopic 6&nail&gel&massage&polish&pedicure&salon&pedi\\\\\\\\\\nTopic 7&customer&order&customer service&minute&order wa&manager&service\\\\\\\\\\nTopic 8&show&car&but&wa&one&get&said\\\\\\\\\\nTopic 9&la&le&de&un&est&dans&je\\\\\\\\\\nTopic 10&minute&u&finally&order&took&waitress&waiting\\\\\\\\\\nTopic 11&club&night&dance&drink&bar&girl&beer\\\\\\\\\\nTopic 12&sandwich&sandwich wa&soup&bread&pie&turkey&chocolate\\\\\\\\\\nTopic 13&great&always&good&but&pretty good&pho&place\\\\\\\\\\nTopic 14&wa&lobster&but&shrimp&pasta&piece&sauce\\\\\\\\\\nTopic 15&bad&food&tasted like&bland&wa&horrible&tasted\\\\\\\\\\nTopic 16&flight&airline&plane&la&fly&airport&ticket\\\\\\\\\\nTopic 17&steak&wa&wine&but&dining&dinner&service wa\\\\\\\\\\nTopic 18&dog&movie&theater&cat&animal&hospital&vet\\\\\\\\\\nTopic 19&company&call&called&would&day&said&sent\\\\\\\\\\nTopic 20&room&stay&front&hotel&night&front desk&desk\\\\\\\\\\nTopic 21&pizza&pepperoni&crust&pizza wa&topping&thin&oven\\\\\\\\\\nTopic 22&room&but&class&lot&gym&wa&floor\\\\\\\\\\nTopic 23&great&amazing&recommend&always&highly&best&beer\\\\\\\\\\nTopic 24&park&seating&coffee&great&bar&outdoor&plenty\\\\\\\\\\nTopic 25&taco&salsa&chip&table&tortilla&u&burrito\\\\\\\\\\nTopic 26&store&item&buy&shoe&selection&dress&sale\\\\\\\\\\nTopic 27&thai&rice&chicken&but&noodle&fried rice&sauce\\\\\\\\\\nTopic 28&lot&chocolate&parking&one&get&yogurt&go\\\\\\\\\\nTopic 29&wa&but&good&wing&wa good&chicken&pretty good\\\\\\\\\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_hstm.visualize_topics(format_pretty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ************************************************************\n",
      "night\n",
      "one\n",
      "but\n",
      "eat\n",
      "1 ************************************************************\n",
      "but\n",
      "one\n",
      "bakery\n",
      "2 ************************************************************\n",
      "cream\n",
      "onion\n",
      "burger wa\n",
      "3 ************************************************************\n",
      "last time\n",
      "donut\n",
      "happy\n",
      "4 ************************************************************\n",
      "e\n",
      "war\n",
      "5 ************************************************************\n",
      "biscuit\n",
      "gravy\n",
      "hash\n",
      "6 ************************************************************\n",
      "polish\n",
      "spa\n",
      "7 ************************************************************\n",
      "customer service\n",
      "minute\n",
      "order wa\n",
      "employee\n",
      "phone\n",
      "8 ************************************************************\n",
      "one\n",
      "said\n",
      "hair\n",
      "people\n",
      "9 ************************************************************\n",
      "un\n",
      "est\n",
      "dans\n",
      "je\n",
      "que\n",
      "10 ************************************************************\n",
      "took\n",
      "waitress\n",
      "waiting\n",
      "another\n",
      "came\n",
      "11 ************************************************************\n",
      "beer\n",
      "but\n",
      "music\n",
      "12 ************************************************************\n",
      "bread\n",
      "turkey\n",
      "bagel\n",
      "13 ************************************************************\n",
      "pretty good\n",
      "pho\n",
      "14 ************************************************************\n",
      "shrimp\n",
      "piece\n",
      "sea\n",
      "15 ************************************************************\n",
      "rice\n",
      "frozen\n",
      "mexican food\n",
      "16 ************************************************************\n",
      "la\n",
      "airway\n",
      "card\n",
      "17 ************************************************************\n",
      "but\n",
      "dining\n",
      "medium\n",
      "night\n",
      "18 ************************************************************\n",
      "care\n",
      "show\n",
      "19 ************************************************************\n",
      "said\n",
      "sent\n",
      "care\n",
      "week\n",
      "20 ************************************************************\n",
      "u\n",
      "21 ************************************************************\n",
      "oven\n",
      "garlic\n",
      "22 ************************************************************\n",
      "lot\n",
      "gym\n",
      "floor\n",
      "shower\n",
      "fun\n",
      "23 ************************************************************\n",
      "best\n",
      "beer\n",
      "great food\n",
      "24 ************************************************************\n",
      "outdoor\n",
      "beer\n",
      "lot\n",
      "25 ************************************************************\n",
      "burrito\n",
      "enchilada\n",
      "26 ************************************************************\n",
      "buy\n",
      "shoe\n",
      "section\n",
      "pair\n",
      "27 ************************************************************\n",
      "but\n",
      "noodle\n",
      "sauce\n",
      "pad\n",
      "delicious\n",
      "28 ************************************************************\n",
      "one\n",
      "la\n",
      "parking lot\n",
      "but\n",
      "29 ************************************************************\n",
      "pretty good\n",
      "pretty\n"
     ]
    }
   ],
   "source": [
    "n_words = 10\n",
    "stm_subset = stm_topics[:,:n_words]\n",
    "hstm_subset = hstm_topics[:,:n_words]\n",
    "\n",
    "for k in range(hstm_subset.shape[0]):\n",
    "    print(k, '*'*60)\n",
    "    for w_idx in hstm_subset[k,:]:\n",
    "        if w_idx not in set(list(stm_subset[k,:])):\n",
    "            print(text_dataset.vocab[int(w_idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
