{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.decomposition import NMF, PCA\n",
    "from sklearn.linear_model import Ridge, LogisticRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_error as mse, roc_auc_score as roc, accuracy_score as acc, log_loss\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data.dataset import TextResponseDataset\n",
    "import causal_attribution\n",
    "import util\n",
    "from scipy.sparse import csr_matrix\n",
    "from importlib import reload\n",
    "import data.dataset as ds\n",
    "from model.topic_model import TopicModel\n",
    "from model.model_trainer import ModelTrainer\n",
    "from torch.utils.data import DataLoader\n",
    "from evaluation.evaluator import Evaluator\n",
    "import itertools as it\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cross_validation(features, labels, num_documents, n_cv=5, n_folds=10, label_is_bool=False, C=None):\n",
    "    n_metrics = 1 if not label_is_bool else 3\n",
    "    split_indices = util.cross_val_splits(num_documents)\n",
    "    all_indices = np.arange(num_documents)\n",
    "    mses = np.zeros((n_cv,n_metrics))\n",
    "    \n",
    "    if label_is_bool:\n",
    "        if C is not None:\n",
    "            model = LogisticRegression(C=C, penalty='l1', solver='liblinear')\n",
    "        else:\n",
    "            model = LogisticRegression(solver='liblinear')\n",
    "    else:\n",
    "        model = Ridge() #Lasso(alpha=C)#\n",
    "    for i in range(n_cv):\n",
    "        te_indices = split_indices[i]\n",
    "        tr_indices = np.setdiff1d(all_indices, te_indices)\n",
    "\n",
    "        tr_feat = features[tr_indices, :]\n",
    "        tr_labels = labels[tr_indices]\n",
    "        te_feat = features[te_indices,:]\n",
    "        te_labels = labels[te_indices]\n",
    "        \n",
    "        model.fit(tr_feat, tr_labels)\n",
    "        \n",
    "        te_pred = model.predict(te_feat)\n",
    "        if label_is_bool:\n",
    "            te_pr_pred = model.predict_proba(te_feat)[:,1]\n",
    "            ll = log_loss(te_labels, te_pr_pred)\n",
    "            auc = roc(te_labels, te_pr_pred)\n",
    "            accuracy = acc(te_labels, te_pred)\n",
    "            mses[i][0] = auc\n",
    "            mses[i][1] = ll\n",
    "            mses[i][2] = accuracy\n",
    "        else:\n",
    "            err = mse(te_labels, te_pred)\n",
    "            mses[i][0] = err\n",
    "    return mses.mean(axis=0), mses.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_model(features, labels, num_documents, split=0, label_is_bool=True):\n",
    "    n_metrics = 1 if not label_is_bool else 3\n",
    "    split_indices = util.cross_val_splits(num_documents)\n",
    "    all_indices = np.arange(num_documents)\n",
    "    if label_is_bool:\n",
    "            model = LogisticRegression(solver='liblinear')\n",
    "    else:\n",
    "        model = Ridge()\n",
    "    i = split\n",
    "    te_indices = split_indices[i]\n",
    "    tr_indices = np.setdiff1d(all_indices, te_indices)\n",
    "\n",
    "    tr_feat = features[tr_indices, :]\n",
    "    tr_labels = labels[tr_indices]\n",
    "    te_feat = features[te_indices,:]\n",
    "    te_labels = labels[te_indices]\n",
    "\n",
    "    model.fit(tr_feat, tr_labels)\n",
    "    return model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_pmi(topics, counts, num_words=10):\n",
    "    num_topics = topics.shape[0]\n",
    "    num_docs = counts.shape[0]\n",
    "    per_topic_npmi = np.zeros(num_topics)\n",
    "\n",
    "    bin_counts = counts.copy()\n",
    "    bin_counts[bin_counts>1] = 1\n",
    "    \n",
    "    tf = csr_matrix(bin_counts)\n",
    "    cooccurence = tf.T.dot(tf)\n",
    "    cooccurence = cooccurence.toarray()\n",
    "\n",
    "    doc_count = bin_counts.sum(axis=0)\n",
    "    prob = doc_count/num_docs\n",
    "    cooccurence_prob = cooccurence/num_docs\n",
    "\n",
    "    for k in range(num_topics):\n",
    "        npmi_total = 0\n",
    "        beta = topics[k,:]\n",
    "        top_words = (-beta).argsort()[:num_words]\n",
    "        n = 0 \n",
    "        for (w1, w2) in it.combinations(top_words, 2):\n",
    "            joint = cooccurence_prob[w1][w2]+1e-7\n",
    "            p_w1 = prob[w1]+1e-7\n",
    "            p_w2 = prob[w2]+1e-7\n",
    "            numerator = np.log(joint/(p_w1*p_w2))\n",
    "            denom = -np.log(joint)\n",
    "            npmi_total += numerator/denom\n",
    "            n+=1\n",
    "        per_topic_npmi[k] = npmi_total\n",
    "    return per_topic_npmi.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 19983, 5974)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(ds)\n",
    "\n",
    "label_is_bool=False\n",
    "dataset = 'amazon'\n",
    "if dataset in TextResponseDataset.CLASSIFICATION_SETTINGS:\n",
    "    label_is_bool=True\n",
    "    \n",
    "framing_topic = 'samesex'\n",
    "\n",
    "if dataset == 'amazon':\n",
    "    datafile = '../dat/reviews_Office_Products_5.json'\n",
    "elif dataset == 'amazon_binary':\n",
    "    datafile = '../dat/reviews_Grocery_and_Gourmet_Food_5.json'\n",
    "elif dataset == 'yelp':\n",
    "    datafile = '../dat/yelp_review_polarity_csv/train.csv'\n",
    "elif dataset == 'peerread':\n",
    "    datafile = '../dat/peerread_abstracts.csv'\n",
    "elif dataset == 'framing_corpus':\n",
    "    datafile = '../dat/framing/'\n",
    "else:\n",
    "    datafile = '../dat/cs_papers.gz'\n",
    "\n",
    "if dataset == 'framing_corpus':\n",
    "    proc_file = '../dat/proc/' + dataset + '_' + framing_topic + '_proc.npz'\n",
    "else:\n",
    "    proc_file = '../dat/proc/' + dataset + '_proc.npz'\n",
    "\n",
    "components = {'amazon':30, \n",
    "              'semantic_scholar':50, \n",
    "              'peerread':50, 'yelp':30, \n",
    "              'amazon_binary':20, \n",
    "              'framing_corpus':10\n",
    "             }\n",
    "text_dataset = ds.TextResponseDataset(dataset, \n",
    "                                      datafile, \n",
    "                                      proc_file, \n",
    "                                      use_bigrams=False,\n",
    "                                      framing_topic=framing_topic)\n",
    "text_dataset.process_dataset()\n",
    "text_dataset.preprocessing()\n",
    "\n",
    "counts = text_dataset.counts\n",
    "labels= text_dataset.labels\n",
    "vocab= text_dataset.vocab\n",
    "docs = text_dataset.docs\n",
    "\n",
    "n_components=components[dataset]\n",
    "num_documents = counts.shape[0]\n",
    "n_components, num_documents, counts.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running PCA on cooccurence matrix of words to create embeddings of words for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.87031551]), array([0.04000839]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = csr_matrix(counts)\n",
    "cooccurence = tf.T.dot(tf)\n",
    "cooccurence = cooccurence.toarray()\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "embeddings = pca.fit_transform(cooccurence)\n",
    "\n",
    "features = np.zeros((num_documents, n_components))\n",
    "for i in range(num_documents):\n",
    "    tf = counts[i,:]\n",
    "    nonzero = (tf > 0)\n",
    "    features[i] = embeddings[nonzero,:].sum(axis=0)\n",
    "\n",
    "result_pca = run_cross_validation(features, labels, num_documents, label_is_bool=label_is_bool)\n",
    "result_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA features for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved results...\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "if dataset == 'framing_corpus':\n",
    "    pretraining_file = '../dat/proc/' + dataset + '_' + framing_topic + '_pretraining.npz'\n",
    "else:\n",
    "    pretraining_file = '../dat/proc/' + dataset + '_pretraining.npz'\n",
    "    \n",
    "if os.path.exists(pretraining_file):\n",
    "    print(\"Loading saved results...\")\n",
    "    arr = np.load(pretraining_file)\n",
    "    doc_rep = arr['theta'] \n",
    "    topics = arr['beta']\n",
    "    print(\"Completed.\")\n",
    "else:\n",
    "    lda_model = LDA(n_components=n_components)\n",
    "    doc_rep = lda_model.fit_transform(counts)\n",
    "    \n",
    "    unnormalized_topics = lda_model.components_\n",
    "    topics = lda_model.components_ / lda_model.components_.sum(axis=1)[:,np.newaxis]\n",
    "    \n",
    "    if dataset == 'framing_corpus':\n",
    "        pretrained_out_file = '../dat/proc/' + dataset + '_' + framing_topic + '_pretraining'\n",
    "    else:\n",
    "        pretrained_out_file = '../dat/proc/' + dataset + '_pretraining'\n",
    "\n",
    "    np.savez_compressed(pretrained_out_file, theta=doc_rep, beta=topics)\n",
    "    \n",
    "    print(\"Perplexity:\", lda_model.perplexity(counts))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: ['wrist', 'rest', 'keyboard', 'but', 'wrist rest', 'use', 'mouse']\n",
      "Topic 1: ['folders', 'file', 'laptop', 'like', 'use', 'file folders', 'keep']\n",
      "Topic 2: ['printer', 'but', 'print', 'paper', 'ink', 'canon', 'epson']\n",
      "Topic 3: ['tape', 'product', 'scotch', 'but', 'much', 'use', 'brand']\n",
      "Topic 4: ['but', 'one', 'get', 'time', 'would', 'could', 'use']\n",
      "Topic 5: ['tape', 'dispenser', 'but', 'use', 'roll', 'one', 'scotch']\n",
      "Topic 6: ['colors', 'great', 'color', 'love', 'green', 'blue', 'bright']\n",
      "Topic 7: ['pencil', 'pencils', 'sharpener', 'lead', 'but', 'one', 'pencil sharpener']\n",
      "Topic 8: ['chair', 'back', 'board', 'but', 'one', 'put', 'wall']\n",
      "Topic 9: ['pen', 'pens', 'ink', 'but', 'markers', 'like', 'writing']\n",
      "Topic 10: ['scanner', 'scan', 'software', 'scanning', 'but', 'use', 'document']\n",
      "Topic 11: ['labels', 'label', 'avery', 'use', 'print', 'but', 'printer']\n",
      "Topic 12: ['shredder', 'monitor', 'but', 'envelopes', 'envelope', 'one', 'shred']\n",
      "Topic 13: ['boxes', 'box', 'storage', 'sturdy', 'but', 'moving', 'easy']\n",
      "Topic 14: ['stapler', 'staples', 'staple', 'one', 'but', 'use', 'like']\n",
      "Topic 15: ['but', 'desk', 'nice', 'would', 'like', 'really', 'looks']\n",
      "Topic 16: ['long', 'quality', 'last', 'time', 'good', 'price', 'long time']\n",
      "Topic 17: ['but', 'use', 'would', 'one', 'hold', 'file', 'used']\n",
      "Topic 18: ['printer', 'print', 'wireless', 'but', 'printing', 'use', 'easy']\n",
      "Topic 19: ['machine', 'pages', 'one', 'use', 'documents', 'binding', 'old']\n",
      "Topic 20: ['label', 'labels', 'use', 'maker', 'batteries', 'label maker', 'but']\n",
      "Topic 21: ['would', 'paper', 'quality', 'recommend', 'would recommend', 'definitely', 'need']\n",
      "Topic 22: ['pad', 'mouse', 'glue', 'mouse pad', 'surface', 'pads', 'but']\n",
      "Topic 23: ['printer', 'paper', 'print', 'printing', 'photo', 'but', 'tray']\n",
      "Topic 24: ['ink', 'cartridges', 'cartridge', 'printer', 'but', 'amazon', 'price']\n",
      "Topic 25: ['binder', 'cover', 'binders', 'plastic', 'pockets', 'but', 'one']\n",
      "Topic 26: ['well', 'use', 'works', 'great', 'laminator', 'home', 'office']\n",
      "Topic 27: ['phone', 'phones', 'system', 'handset', 'base', 'but', 'cell']\n",
      "Topic 28: ['notes', 'tabs', 'sticky', 'note', 'tab', 'use', 'write']\n",
      "Topic 29: ['paper', 'cards', 'but', 'cut', 'card', 'sheets', 'use']\n"
     ]
    }
   ],
   "source": [
    "for k in range(n_components):\n",
    "    beta = topics[k]\n",
    "    top_words = (-beta).argsort()[:7]\n",
    "    topic_words = [(vocab[t]) for t in top_words]\n",
    "    print('Topic {}: {}'.format(k, topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.90287184]), array([0.0456039]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log_doc_rep = np.log(doc_rep)\n",
    "results_lda = run_cross_validation(doc_rep, labels, num_documents, label_is_bool=label_is_bool)\n",
    "results_lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW features for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = counts/counts.sum(axis=1)[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.7947163]), array([0.03868611]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_bow = run_cross_validation(csr_matrix(normalized), labels, num_documents, label_is_bool=label_is_bool)\n",
    "result_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression adjusted for topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.78526835]), array([0.0396207]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.column_stack((normalized,doc_rep))\n",
    "result_adjusted = run_cross_validation(csr_matrix(features), labels, num_documents, label_is_bool=label_is_bool)\n",
    "result_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
